## [ğŸ“” L1_Course_Introduction]

#### Multi-Modal vs. Multi-Medium
> - **Modality**
> : (ì´ë¯¸ ì¼ì–´ë‚¬ê±°ë‚˜ ê²½í—˜ëœ) íŠ¹ì • íƒ€ì…ì˜ ì •ë³´ or ì •ë³´ê°€ ì €ì¥ë˜ëŠ” representation format
> <br>(e.g. Natural language, Visual, Auditory, Haptics/touch, Smell, taste, 
> self-motion, Physiological signals, etc)
> <br> - **Medium**
> : ì •ë³´ ì €ì¥ or í†µì‹ ì„ ìœ„í•œ ìˆ˜ë‹¨/ë„êµ¬

#### 4 eras of Multimodal research
> 1. The **"behavioral"** era (1970s ~ late 1980s): McGurk effect ë°œê²¬...!(í•˜ë‚˜ì˜ modalityë§Œìœ¼ë¡œëŠ” ìª¼ê¼¼ í˜ë“¤ê² ë‹¤~)
> 2. The **"computational"** era (late 1980s ~ 2000): Audio-Visual Speech Recognition, Multimodal/Multisensory interfaces, Multimedia Computing
> 3. The **"interaction"** era (2000 ~ 2010): Modeling Human Multimodal Interaction(e.g. Siri)
> 4. The **"deep learning"** era (2010s ~): Representation learning(New large-scale multimodal datasets, improvement of computing power, high-level visual features, "dimensional" linguistic features)

#### Core Technical Challenges
> ![image](https://user-images.githubusercontent.com/33504288/124376247-04ba4280-dce1-11eb-8cc4-e4ff031e4d47.png)
> _Representation ë½‘ì•„ì„œ Alignmentí•˜ê³  Translation or Fusioní•œ ë’¤_ 
> > ì—¬ê¸°ì„œ Translationê³¼ Fusionì€ loss functionì„ ë­˜ ì“°ëŠëƒ~ ì˜ ì°¨ì´
> > - translation: í•˜ë‚˜ì˜ modal ì •ë³´ë¥¼ ë‹¤ë¥¸ modalë¡œ ë°”ê¾¸ê¸°(e.g. image captioning)
> > - fusion: ëª¨ë“  modalì„ ì‚¬ìš©í•´ì„œ high-levelì˜ ë¬´ì–¸ê°€ë¡œ ì¶”ë¡ (e.g. emotion recognition, detecting an event in a video)

#### ğŸŒŸ **Representation**: multimodal dataë¥¼ ì–´ë–»ê²Œ í‘œí˜„í•˜ê³  ìš”ì•½í•˜ì§€?
 ![image](https://user-images.githubusercontent.com/33504288/124375456-3c26f000-dcdd-11eb-80f4-460370c3f7cc.png)
> - Joint representations<br>
> : multimodal representationì„ concatí•´ì„œ ì‚¬ìš©
> - Coordinated representations<br>
> : ê° modalì˜ representationì—ì„œ í•„ìš”í•œ ë¶€ë¶„ë“¤ë§Œ ë½‘ì•„ì„œ ì‚¬ìš©

#### ğŸŒŸ **Alignment**:ë‹¤ë¥¸ modalì—ì„œ ë‚˜ì˜¨ (sub)elenment ê°„ì˜ ì§ì ‘ì ì¸ ê´€ê³„ ì‹ë³„
![image](https://user-images.githubusercontent.com/33504288/124375628-31208f80-dcde-11eb-898e-4da368a0f541.png)
> - Explicit Alignment<br>
> : modal ê°„ ì§ì ‘ì ìœ¼ë¡œ ëŒ€ì‘ë˜ëŠ” ë‚´ìš© matching(audio:"ì‚¬ê³¼" -> image:ì‚¬ê³¼ ì‚¬ì§„)
> - Implicit Alignment<br>
> : ë‹¤ë¥¸ ë¬¸ì œë¥¼ ë” ì˜ í’€ê¸° ìœ„í•´ ë‚´ë¶€ì ìœ¼ë¡œ ì ì¬ëœ(latent) alignment ì‚¬ìš©(Attention ëª¨ë¸ì´ë‘ ë¹„ìŠ·!)
> ![image](https://user-images.githubusercontent.com/33504288/124376074-2c5cdb00-dce0-11eb-8783-e7c9c4c7fa1f.png)

#### ğŸŒŸ **Translation**: 
